{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from the text file into a DataFrame\n",
    "data = pd.read_csv('KGs/UMLS/train.txt', header=None, sep='\\t', names=['Head', 'Relation', 'Tail'])\n",
    "\n",
    "# Prepare a list to store counts\n",
    "counts = []\n",
    "\n",
    "# Iterate through each tuple in the DataFrame\n",
    "for index, row in data.iterrows():\n",
    "    # Count how many tuples have the same relation and tail\n",
    "    count = ((data['Relation'] == row['Relation']) & (data['Tail'] == row['Tail'])).sum()\n",
    "    # Append the count to the list\n",
    "    counts.append(count)\n",
    "\n",
    "# Create a new DataFrame from the counts\n",
    "counts_df = pd.DataFrame(counts, columns=['Count'])\n",
    "\n",
    "# Save the counts DataFrame to a new text file\n",
    "counts_df.to_csv('KGs/UMLS/counts.txt', index=False, header=False)\n",
    "\n",
    "# Print a confirmation message\n",
    "print(\"Counts have been saved to counts.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and aligned data has been written to /Users/abhayvaghasiya/Desktop/WORK/cleaned_output.txt\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define the input and output file paths\n",
    "input_file = '/Users/abhayvaghasiya/Desktop/WORK/output_file_perturbed_KG_without_isA-1(1).txt'\n",
    "output_file = '/Users/abhayvaghasiya/Desktop/WORK/cleaned_output.txt'\n",
    "\n",
    "# Open the input file for reading and the output file for writing\n",
    "with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "    for line in infile:\n",
    "        # Use regex to remove the URL-like structures\n",
    "        cleaned_line = re.sub(r'<https://dice-research.org/(\\w+)>', r'\\1', line)\n",
    "        \n",
    "        # Split the cleaned line into components (entity, relation, value)\n",
    "        components = cleaned_line.split()\n",
    "        \n",
    "        if len(components) == 4:  # Ensure there are 3 elements plus a value\n",
    "            # Join the parts with tabs and write to the output file\n",
    "            formatted_line = '\\t'.join(components[:3]) + '\\t' + components[3] + '\\n'\n",
    "            outfile.write(formatted_line)\n",
    "\n",
    "print(f\"Cleaned and aligned data has been written to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapped tuples have been written to /Users/abhayvaghasiya/Desktop/WORK/mapped_tuples.txt\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load entity and relation mappings\n",
    "with open('/Users/abhayvaghasiya/Desktop/WORK/dice_repos/dice-embeddings_loss_function/Experiments/2024-09-26 01-49-44.486888/entity_to_idx.p', 'rb') as f:\n",
    "    entity_to_idx = pickle.load(f)\n",
    "\n",
    "with open('/Users/abhayvaghasiya/Desktop/WORK/dice_repos/dice-embeddings_loss_function/Experiments/2024-09-26 01-49-44.486888/relation_to_idx.p', 'rb') as f:\n",
    "    relation_to_idx = pickle.load(f)\n",
    "\n",
    "# Function to map an entity or relation to its index\n",
    "def get_index(mapping, item, item_type):\n",
    "    formatted_item = item.lower().replace(' ', '_')\n",
    "    if formatted_item in mapping:\n",
    "        return mapping[formatted_item]\n",
    "    else:\n",
    "        print(f\"Warning: {item_type} '{item}' not found in mapping.\")\n",
    "        return None\n",
    "\n",
    "# Define the output file path\n",
    "output_file_path = '/Users/abhayvaghasiya/Desktop/WORK/mapped_tuples.txt'\n",
    "\n",
    "# Read the train.txt file and map tuples to indices, writing results to output file\n",
    "with open('/Users/abhayvaghasiya/Desktop/WORK/UMLS/train.txt', 'r') as train_file, \\\n",
    "     open(output_file_path, 'w') as output_file:\n",
    "    \n",
    "    for line in train_file:\n",
    "        head, relation, tail = line.strip().split('\\t')\n",
    "        \n",
    "        head_idx = get_index(entity_to_idx, head, \"Entity\")\n",
    "        relation_idx = get_index(relation_to_idx, relation, \"Relation\")\n",
    "        tail_idx = get_index(entity_to_idx, tail, \"Entity\")\n",
    "        \n",
    "        if head_idx is not None and relation_idx is not None and tail_idx is not None:\n",
    "            # Write the tuple with tabs and format the indices as a list\n",
    "            output_file.write(f\"{head}\\t{relation}\\t{tail}\\t[{head_idx}, {relation_idx}, {tail_idx}]\\n\")\n",
    "\n",
    "print(f\"Mapped tuples have been written to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched tuples have been written to /Users/abhayvaghasiya/Desktop/WORK/matched_tuples.txt\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for both input files and the output file\n",
    "file1 = '/Users/abhayvaghasiya/Desktop/WORK/mapped_tuples.txt'  # File with tuples and indices\n",
    "file2 = '/Users/abhayvaghasiya/Desktop/WORK/scaled_cleaned_output.txt'  # File with tuples and values\n",
    "output_file = '/Users/abhayvaghasiya/Desktop/WORK/matched_tuples.txt'\n",
    "\n",
    "# Read the contents of both files into dictionaries for easy lookup\n",
    "mapped_tuples = {}\n",
    "with open(file1, 'r') as f1:\n",
    "    for line in f1:\n",
    "        # Split by tab, assuming the format is head\\trelation\\ttail\\t[indices]\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 4:\n",
    "            key = f\"{parts[0]}\\t{parts[1]}\\t{parts[2]}\"  # Create the key from the tuple\n",
    "            mapped_tuples[key] = parts[3]  # Store the indices as the value\n",
    "\n",
    "# Open the second file and the output file for writing\n",
    "with open(file2, 'r') as f2, open(output_file, 'w') as outfile:\n",
    "    for line in f2:\n",
    "        # Split by tab, assuming the format is head\\trelation\\ttail\\tvalue\n",
    "        parts = line.strip().split('\\t')\n",
    "        if len(parts) == 4:\n",
    "            key = f\"{parts[0]}\\t{parts[1]}\\t{parts[2]}\"  # Create the key from the tuple\n",
    "            value = parts[3]  # Get the value\n",
    "\n",
    "            # If the tuple exists in both files, write the result\n",
    "            if key in mapped_tuples:\n",
    "                outfile.write(f\"{mapped_tuples[key]}\\t{value}\\n\")\n",
    "\n",
    "print(f\"Matched tuples have been written to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
